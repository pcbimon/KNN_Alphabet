{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries and defining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For capturing hand coordinates\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# For processing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#For check file\n",
    "import os\n",
    "import time\n",
    "import webbrowser\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('./Dataset/hand_dataset_1000_24.csv')\n",
    "# dataset = pd.read_csv('./Dataset/hand_dataset_3000.csv')\n",
    "dataset = pd.read_csv('./Dataset/hand_dataset_MAI_3000.csv')\n",
    "# dataset = pd.read_csv('./Dataset/hand_dataset_MAI_3000_space_del.csv')\n",
    "\n",
    "# Show dataset first five data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset overview, should return 1000 for each alphabet (excluding y and z)\n",
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating Train and Test Data\n",
    "- We use *train_test_split* since we don't really have test dataset.\n",
    "- Normalizing dataset can be ignored, since we predict our data directly using raw handlandmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y from dataset for training and testing\n",
    "\n",
    "X = dataset.iloc[:, 1:].values\n",
    "Y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We will take 33% from 1000 for our test data.\n",
    "# Recommended value 80:20, 67:33, 50:50\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize / Standarize dataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating classifier model for our alphabet recognition.\n",
    "- *n_neighbors* can be adjusted as we provide graph for mean errors for each *n_neighbors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Show graph for adjusting number of *n_neighbors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Intialize Mediapipe Hands for alphabet recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mediapipe hand\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# init Check Var MAI\n",
    "M = False\n",
    "A = False\n",
    "I = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count File In Folder\n",
    "def countFile(Ipath):\n",
    "    initial_count = 0\n",
    "    for path in os.listdir(Ipath):\n",
    "        if os.path.isfile(os.path.join(Ipath, path)):\n",
    "            initial_count += 1\n",
    "    return initial_count\n",
    "# Create Function to Detect complete label \"M\",\"A\",\"I\"\n",
    "def isComplete():\n",
    "    if(M == True and A == True and I == True):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def checkAlpha(alph):\n",
    "    global M\n",
    "    global A\n",
    "    global I\n",
    "    if(str(alph) == \"M\" and M == False):\n",
    "        M = True\n",
    "    if(str(alph) == \"A\" and A == False):\n",
    "        A = True\n",
    "    if(str(alph) == \"I\" and I == False):\n",
    "        I = True\n",
    "def DisplayCheckAlpha():\n",
    "    global M\n",
    "    global A\n",
    "    global I\n",
    "    result = \"_|_|_\"\n",
    "    arr = result.split(\"|\");\n",
    "    if(M==True):\n",
    "        arr[0]=\"M\"\n",
    "    if(A==True):\n",
    "        arr[1]=\"A\"\n",
    "    if(I==True):\n",
    "        arr[2]=\"I\"\n",
    "    print(\"M : \"+str(M)+\" A : \"+str(A)+\" I : \"+str(I))\n",
    "    return arr[0]+arr[1]+arr[2]\n",
    "# Write detect file\n",
    "def writeFile(iAlpha,img):\n",
    "    BasePath = \"./archive/ceremony/\"+iAlpha\n",
    "    isExist = os.path.exists(BasePath)\n",
    "    if not isExist:\n",
    "        os.makedirs(BasePath)\n",
    "    cv2.imwrite(os.path.join(BasePath, f'{countFile(BasePath):04d}' +'.jpg'), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mediapipe hand capture webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    start_time = time.time()\n",
    "    DELAY_SECONDS = 5\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # Get status box\n",
    "        cv2.rectangle(image, (0,0), (200, 70), (245, 90, 16), -1)\n",
    "        cv2.putText(image, DisplayCheckAlpha(), (20,25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        # Display Class\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                coords = hand_landmarks.landmark\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                coords = list(np.array([[landmark.x, landmark.y] for landmark in coords]).flatten())\n",
    "#                 coords = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in coords]).flatten())\n",
    "                coords = scaler.transform([coords])\n",
    "                \n",
    "                # Alternative for dataset using z coordinates.\n",
    "                # Z coordinates is not recommended, since you need to adjust your distance from camera.\n",
    "                \n",
    "                \n",
    "                predicted = classifier.predict(coords)\n",
    "\n",
    "            cv2.putText(image, \"Found : \"+str(predicted[0])\n",
    "                        , (20,55), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            if(len(predicted) > 0):\n",
    "                # writeFile(predicted[0],image)\n",
    "                checkAlpha(predicted[0]);\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "#         if(isComplete() == True):\n",
    "#             break\n",
    "        # Press esc to close webcam\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "if(isComplete() == True):\n",
    "    webbrowser.open(\"https://www.youtube.com/watch?v=GaKNGh9JK2k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

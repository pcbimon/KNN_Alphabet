{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install scikit-learn\n",
    "!pip install cvzone\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries and defining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For capturing hand coordinates\n",
    "import cv2\n",
    "import cvzone\n",
    "import mediapipe as mp\n",
    "\n",
    "# For processing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#For check file\n",
    "import os\n",
    "import time\n",
    "import webbrowser\n",
    "\n",
    "#resize image\n",
    "import imutils\n",
    "import tkinter as tk\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('celemony.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS config\n",
    "               (title text, amount INTEGER)''')\n",
    "cur.execute(\"select * from config where title=:title\", {\"title\": \"p1ByPass\"})\n",
    "# check p1ByPass\n",
    "data = cur.fetchall()\n",
    "if len(data) == 0:\n",
    "    print('init p1ByPass')\n",
    "    cur.execute(\"insert into config values (?,?)\", [(\"p1ByPass\"),(\"0\")])\n",
    "    con.commit()\n",
    "cur.execute(\"select * from config where title=:title\", {\"title\": \"p2ByPass\"})\n",
    "# check p1ByPass\n",
    "data = cur.fetchall()\n",
    "if len(data) == 0:\n",
    "    cur.execute(\"insert into config values (?,?)\", [(\"p2ByPass\"),(\"0\")])\n",
    "    con.commit()\n",
    "    print('init p2ByPass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('./Dataset/hand_dataset_1000_24.csv')\n",
    "dataset = pd.read_csv('./Dataset/hand_dataset_3000.csv')\n",
    "# dataset = pd.read_csv('./Dataset/hand_dataset_MAI_3000.csv')\n",
    "# dataset = pd.read_csv('./Dataset/hand_dataset_MAI_3000_space_del.csv')\n",
    "\n",
    "# Show dataset first five data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset overview, should return 1000 for each alphabet (excluding y and z)\n",
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating Train and Test Data\n",
    "- We use *train_test_split* since we don't really have test dataset.\n",
    "- Normalizing dataset can be ignored, since we predict our data directly using raw handlandmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y from dataset for training and testing\n",
    "\n",
    "X = dataset.iloc[:, 1:].values\n",
    "Y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We will take 33% from 1000 for our test data.\n",
    "# Recommended value 80:20, 67:33, 50:50\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize / Standarize dataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating classifier model for our alphabet recognition.\n",
    "- *n_neighbors* can be adjusted as we provide graph for mean errors for each *n_neighbors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Show graph for adjusting number of *n_neighbors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Intialize Mediapipe Hands for alphabet recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mediapipe hand\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# init Check Var MAI\n",
    "M = False\n",
    "A = False\n",
    "I = False\n",
    "\n",
    "#static var\n",
    "onProcessingVideo = \"./images/static/OnLoading.mp4\"\n",
    "\n",
    "#check on success\n",
    "isSuccess = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "root = tk.Tk()\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "window_width = screen_width/2\n",
    "window_height = screen_height-30\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "# Count File In Folder\n",
    "def countFile(Ipath):\n",
    "    initial_count = 0\n",
    "    for path in os.listdir(Ipath):\n",
    "        if os.path.isfile(os.path.join(Ipath, path)):\n",
    "            initial_count += 1\n",
    "    return initial_count\n",
    "# Create Function to Detect complete label \"M\",\"A\",\"I\"\n",
    "def isComplete():\n",
    "    if(M == True and A == True and I == True):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def checkAlpha(alph,checkOnLabel):\n",
    "    global result\n",
    "    result.append(alph)\n",
    "    if(len(result)>=2):\n",
    "        if(result[len(result)-1] == result[len(result)-2] and result[len(result)-1] == checkOnLabel):\n",
    "            return True\n",
    "        else:\n",
    "            result.clear()\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "def DisplayCheckAlpha():\n",
    "    global M\n",
    "    global A\n",
    "    global I\n",
    "    result = \"_|_|_\"\n",
    "    arr = result.split(\"|\");\n",
    "    if(M==True):\n",
    "        arr[0]=\"M\"\n",
    "    if(A==True):\n",
    "        arr[1]=\"A\"\n",
    "    if(I==True):\n",
    "        arr[2]=\"I\"\n",
    "    print(\"M : \"+str(M)+\" A : \"+str(A)+\" I : \"+str(I))\n",
    "    return arr[0]+arr[1]+arr[2]\n",
    "# Write detect file\n",
    "def writeFile(iAlpha,img):\n",
    "    BasePath = \"./archive/ceremony/\"+iAlpha\n",
    "    isExist = os.path.exists(BasePath)\n",
    "    if not isExist:\n",
    "        os.makedirs(BasePath)\n",
    "    cv2.imwrite(os.path.join(BasePath, f'{countFile(BasePath):04d}' +'.jpg'), img)\n",
    "def __draw_label(img, text, pos, bg_color,text_color=(0, 0, 0)):\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 5\n",
    "    color = text_color\n",
    "    thickness = cv2.FILLED\n",
    "    margin = 2\n",
    "\n",
    "    txt_size = cv2.getTextSize(text, font_face, scale, thickness)\n",
    "\n",
    "    end_x = pos[0] + txt_size[0][0] + margin\n",
    "    end_y = pos[1] - txt_size[0][1] - margin-20\n",
    "\n",
    "    cv2.rectangle(img, (pos[0],pos[1]+20), (end_x, end_y), bg_color, thickness)\n",
    "    cv2.putText(img, text, pos, font_face, scale, color, 10, cv2.LINE_AA)\n",
    "def rescale_frame(frame):\n",
    "    global screen_width,screen_height,window_width,window_height\n",
    "    frame_width = int(frame.shape[1])\n",
    "    frame_height = int(frame.shape[0])\n",
    "    #crop image\n",
    "    crop_width = (frame_height/window_height)*window_width\n",
    "    crop_height = frame_height\n",
    "    x1 = (frame_width/2)-(crop_width/2)\n",
    "    x2 = (frame_width/2)+(crop_width/2)\n",
    "    frame_croped = frame[0:int(frame_height), int(x1):int(x2)]\n",
    "    #resize image\n",
    "    dim = (int(window_width), int(window_height))\n",
    "    return cv2.resize(frame_croped, dim, interpolation =cv2.INTER_AREA)\n",
    "def startXPosition(index):\n",
    "    xList = [0,0,0]\n",
    "    root = tk.Tk()\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "    for i in range(len(xList)):\n",
    "        if(i > 0):\n",
    "            xList[i] = xList[i-1]+int(screen_width/2)\n",
    "    return xList[index]\n",
    "def playOnProcessingVideo(webcamFrame,cap_vid,esmateTime,time_passed):\n",
    "    global onProcessingVideo\n",
    "    #return webcamFrame\n",
    "    if esmateTime>0:\n",
    "        # Video feed\n",
    "        ret, frame_vid = cap_vid.read()\n",
    "        if not ret:\n",
    "            print('Cannot open video stream: ' + filename)\n",
    "            cap_vid.release()\n",
    "            exit()\n",
    "        ret = cap_vid.set(cv2.CAP_PROP_POS_MSEC, time_passed)\n",
    "        if not ret:\n",
    "            print('An error occured while setting video time')\n",
    "            exit()\n",
    "        # Rescale \n",
    "        frame_vid = rescale_frame(frame_vid)\n",
    "        # Blend the two images and show the result\n",
    "        tr = 0.5 # transparency between 0-1, show camera if 0 \n",
    "        frame = ((1-tr) * webcamFrame.astype(np.float64) + tr * frame_vid.astype(np.float64)).astype(np.uint8)\n",
    "        return frame\n",
    "    else:\n",
    "        return webcamFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentProjectLabel = \"A\"\n",
    "alphabetHand = cv2.imread('./images/static/'+currentProjectLabel+'_Hand_final.png', cv2.IMREAD_UNCHANGED)\n",
    "passImage = cv2.imread('./images/static/Aplha_'+currentProjectLabel+'.png', cv2.IMREAD_UNCHANGED)\n",
    "passImage = cv2.resize(passImage,(0,0),None,0.3,0.3)\n",
    "alphabetHand = cv2.resize(alphabetHand,(0,0),None,0.3,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectionAlpha(currentProjectLabel,videoRecorderIndex,windowpositionX,windowpositionY):\n",
    "    con = sqlite3.connect('celemony.db')\n",
    "    processName = \"p\"+str((videoRecorderIndex+1))+\"ByPass\"\n",
    "    cap = cv2.VideoCapture(videoRecorderIndex)\n",
    "    success,img = cap.read()\n",
    "    isStartCheck = False\n",
    "    enableByPass = False\n",
    "    byPass = False\n",
    "    global alphabetHand,passImage\n",
    "    global isSuccess\n",
    "    checkedImg = passImage\n",
    "    overlay = alphabetHand\n",
    "    hf,wh,cf = overlay.shape\n",
    "    hc,wc,cc = checkedImg.shape\n",
    "    captureImg = img\n",
    "    prepareWin = \"Hand Tracking - \"+currentProjectLabel\n",
    "    displayResultWindowName = \"Display Result - \"+currentProjectLabel\n",
    "    isComplete = False\n",
    "    #video on Processing \n",
    "    filename = onProcessingVideo\n",
    "    cap_vid = cv2.VideoCapture(filename)\n",
    "    with mp_hands.Hands(\n",
    "        max_num_hands = 1,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "        start_time = time.time()\n",
    "        DELAY_SECONDS = 1\n",
    "        t1 = time.time()\n",
    "        while cap.isOpened():\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"select * from config where title='\"+processName+\"'\")\n",
    "            data = cur.fetchall()\n",
    "            if data[0][1] == 1:\n",
    "                byPass = True\n",
    "            else:\n",
    "                byPass = False\n",
    "            success, image = cap.read()\n",
    "            # resize image\n",
    "            image = rescale_frame(image)\n",
    "            hb,wb,cb = image.shape\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "            # Flip the image horizontally for a later selfie-view display, and convert\n",
    "            # the BGR image to RGB.\n",
    "            #image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            results = hands.process(image)\n",
    "\n",
    "            # Draw the hand annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw Alphabet and Hand\n",
    "#             __draw_label(image, currentProjectLabel, (wb-100,150), (255,255,255))\n",
    "            image = cvzone.overlayPNG(image,overlay,[0,0])\n",
    "\n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,hb-80), (200, hb), (245, 90, 16), -1)\n",
    "    #         cv2.putText(image, DisplayCheckAlpha(), (20,25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # Display Class\n",
    "            isSameAlpha = False\n",
    "            key = cv2.waitKey(1)\n",
    "            if not results.multi_hand_world_landmarks:\n",
    "                t1 = time.time()\n",
    "                isStartCheck = False\n",
    "            if(byPass == True):\n",
    "                cv2.putText(image, \"*\"\n",
    "                                , (wb-30,hb-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    coords = hand_landmarks.landmark\n",
    "                    mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    coords = list(np.array([[landmark.x, landmark.y] for landmark in coords]).flatten())\n",
    "    #                 coords = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in coords]).flatten())\n",
    "                    coords = scaler.transform([coords])\n",
    "\n",
    "                    # Alternative for dataset using z coordinates.\n",
    "                    # Z coordinates is not recommended, since you need to adjust your distance from camera.\n",
    "\n",
    "\n",
    "                    predicted = classifier.predict(coords)\n",
    "                if(byPass == False):\n",
    "                    cv2.putText(image, \"Found : \"+str(predicted[0])\n",
    "                                , (20,hb-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                    if(len(predicted) > 0):\n",
    "                        isSameAlpha = checkAlpha(predicted[0],currentProjectLabel)\n",
    "                        if(isSameAlpha == True and isStartCheck == False):\n",
    "                            t1 = time.time()\n",
    "                            isStartCheck = True\n",
    "                        if(isSameAlpha == True and isStartCheck == True):\n",
    "                            duration = time.time()-t1\n",
    "                            esmateTime = (DELAY_SECONDS - duration)\n",
    "                            if(esmateTime < 0):\n",
    "                                esmateTime = 0\n",
    "                            cv2.putText(image, format(esmateTime, '.0f')\n",
    "                                , (wb-40,hb-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "                            # insert video in waiting delay time\n",
    "                            image = playOnProcessingVideo(image,cap_vid,esmateTime,duration*1000)\n",
    "                            if(duration >=DELAY_SECONDS and isSuccess == False):\n",
    "                                print(\"Checked\")\n",
    "                                t1 = time.time()\n",
    "                                isStartCheck = False\n",
    "                                # Capture image and Display\n",
    "                                writeFile(currentProjectLabel,image)\n",
    "                                captureImg = image\n",
    "                                isComplete = True\n",
    "                                # __draw_label(captureImg, currentProjectLabel, (wb-100,150), (0,128,0),(255, 255, 255))\n",
    "                                captureImg = cvzone.overlayPNG(captureImg,checkedImg,[int(wb/2)-50,hb-hc-20])\n",
    "\n",
    "                                cv2.imshow(displayResultWindowName, captureImg)\n",
    "                                # Move window to position\n",
    "                                cv2.moveWindow(displayResultWindowName,windowpositionX,windowpositionY)\n",
    "                                isSuccess = True\n",
    "                        #Reset when not same\n",
    "                        if(isSameAlpha == False and isStartCheck == True):\n",
    "                            t1 = time.time()\n",
    "                            isStartCheck = False\n",
    "                else:\n",
    "                    cv2.putText(image, \"Found : \"+str(currentProjectLabel)\n",
    "                                , (20,hb-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                    isSameAlpha = checkAlpha(currentProjectLabel,currentProjectLabel)\n",
    "                    if(isStartCheck == False):\n",
    "                        t1 = time.time()\n",
    "                        isStartCheck = True\n",
    "                        # print('Start Time : '+str(t1))\n",
    "                    if(isStartCheck == True):\n",
    "                        curTime = time.time()\n",
    "                        duration = curTime -t1\n",
    "                        # print('Current Time : '+str(curTime))\n",
    "                        # print('duration : '+str(duration))\n",
    "                        esmateTime = (DELAY_SECONDS - duration)\n",
    "                        if(esmateTime < 0):\n",
    "                            esmateTime = 0\n",
    "                        cv2.putText(image, format(esmateTime, '.0f')\n",
    "                            , (wb-40,hb-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "                        # insert video in waiting delay time\n",
    "                        image = playOnProcessingVideo(image,cap_vid,esmateTime,duration*1000)\n",
    "                        if(duration >=DELAY_SECONDS):\n",
    "                            print(\"Checked\")\n",
    "                            t1 = time.time()\n",
    "                            isStartCheck = False\n",
    "                            # Capture image and Display\n",
    "                            writeFile(currentProjectLabel,image)\n",
    "                            captureImg = image\n",
    "                            isComplete = True\n",
    "                            # __draw_label(captureImg, currentProjectLabel, (wb-100,150), (0,128,0),(255, 255, 255))\n",
    "                            captureImg = cvzone.overlayPNG(captureImg,checkedImg,[int(wb/2)-50,hb-hc-20])\n",
    "\n",
    "                            cv2.imshow(displayResultWindowName, captureImg)\n",
    "                            # Move window to position\n",
    "                            cv2.moveWindow(displayResultWindowName,windowpositionX,windowpositionY)\n",
    "                            isSuccess = True\n",
    "                            byPass = False\n",
    "                            cur.execute(\"update config set amount=0 where title='\"+processName+\"'\")\n",
    "                            con.commit()\n",
    "            try:\n",
    "                cv2.imshow(prepareWin, image)\n",
    "                # Move window to position\n",
    "                cv2.moveWindow(prepareWin,windowpositionX,windowpositionY)\n",
    "            except:\n",
    "                print(\"Error on Creating Capture\")\n",
    "            key = cv2.waitKey(5)\n",
    "            if key & 0xFF == ord(currentProjectLabel.lower()):\n",
    "                try:\n",
    "                    cv2.destroyWindow(displayResultWindowName)\n",
    "                    isSuccess = False\n",
    "                    print(displayResultWindowName + \" is closed\")\n",
    "                except:\n",
    "                    print(displayResultWindowName + \" is not opened\")\n",
    "            # when closed result\n",
    "            if(cv2.getWindowProperty(prepareWin,cv2.WND_PROP_VISIBLE)==1 and cv2.getWindowProperty(displayResultWindowName,cv2.WND_PROP_VISIBLE)==0):\n",
    "                isSuccess = False\n",
    "            # wait multiple key\n",
    "            pressedKey = cv2.waitKey(5) & 0xFF\n",
    "            if pressedKey == ord(str(videoRecorderIndex+1)):\n",
    "                if enableByPass == True:\n",
    "                    byPass = True\n",
    "                    cur.execute(\"update config set amount=1 where title='\"+processName+\"'\")\n",
    "                    con.commit()\n",
    "                    print('Bypass was running')\n",
    "                else:\n",
    "                    print('Bypass has Disable')\n",
    "            elif pressedKey == ord('p'):\n",
    "                enableByPass = True\n",
    "                print('Bypass has Enable')\n",
    "            # on press esc to quit\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start Detection function\n",
    "global currentProjectLabel\n",
    "print(currentProjectLabel)\n",
    "DetectionAlpha(currentProjectLabel,0,startXPosition(0),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
